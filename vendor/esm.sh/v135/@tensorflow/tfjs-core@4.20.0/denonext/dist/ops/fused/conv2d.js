/* esm.sh - esbuild bundle(@tensorflow/tfjs-core@4.20.0/dist/ops/fused/conv2d) denonext production */
import{ENGINE as y}from"/v135/@tensorflow/tfjs-core@4.20.0/denonext/dist/engine.js";import{customGrad as A}from"/v135/@tensorflow/tfjs-core@4.20.0/denonext/dist/gradients.js";import{FusedConv2D as I}from"/v135/@tensorflow/tfjs-core@4.20.0/denonext/dist/kernel_names.js";import{makeTypesMatch as F}from"/v135/@tensorflow/tfjs-core@4.20.0/denonext/dist/tensor_util.js";import{convertToTensor as C}from"/v135/@tensorflow/tfjs-core@4.20.0/denonext/dist/tensor_util_env.js";import*as r from"/v135/@tensorflow/tfjs-core@4.20.0/denonext/dist/util.js";import{add as K}from"/v135/@tensorflow/tfjs-core@4.20.0/denonext/dist/ops/add.js";import*as W from"/v135/@tensorflow/tfjs-core@4.20.0/denonext/dist/ops/broadcast_util.js";import{conv2d as R}from"/v135/@tensorflow/tfjs-core@4.20.0/denonext/dist/ops/conv2d.js";import{conv2DBackpropFilter as V}from"/v135/@tensorflow/tfjs-core@4.20.0/denonext/dist/ops/conv2d_backprop_filter.js";import{conv2DBackpropInput as j}from"/v135/@tensorflow/tfjs-core@4.20.0/denonext/dist/ops/conv2d_backprop_input.js";import*as p from"/v135/@tensorflow/tfjs-core@4.20.0/denonext/dist/ops/conv_util.js";import{applyActivation as q,getFusedBiasGradient as z,getFusedDyActivation as J,shouldFuse as M}from"/v135/@tensorflow/tfjs-core@4.20.0/denonext/dist/ops/fused_util.js";import{op as Q}from"/v135/@tensorflow/tfjs-core@4.20.0/denonext/dist/ops/operation.js";import{reshape as N}from"/v135/@tensorflow/tfjs-core@4.20.0/denonext/dist/ops/reshape.js";function X({x:_,filter:w,strides:l,pad:d,dataFormat:a="NHWC",dilations:c=[1,1],dimRoundingMode:b,bias:$,activation:m="linear",preluActivationWeights:D,leakyreluAlpha:H}){if(m=m||"linear",M(y.state.gradientDepth,m)===!1){r.assert(a==="NHWC",()=>`Error in fused conv2d: got dataFormat of ${a} but only NHWC is currently supported for the case of gradient depth is 0 and the activation is not linear.`);let t=R(_,w,l,d,a,c,b);return $!=null&&(t=K(t,$)),q(t,m,D,H)}let h=C(_,"x","conv2d","float32"),u=C(w,"filter","conv2d","float32"),n=h,E=!1;h.rank===3&&(E=!0,n=N(h,[1,h.shape[0],h.shape[1],h.shape[2]])),r.assert(n.rank===4,()=>`Error in fused conv2d: input must be rank 4, but got rank ${n.rank}.`),r.assert(u.rank===4,()=>`Error in fused conv2d: filter must be rank 4, but got rank ${u.rank}.`),p.checkPadOnDimRoundingMode("fused conv2d",d,b);let O=a==="NHWC"?n.shape[3]:n.shape[1];r.assert(u.shape[2]===O,()=>`Error in conv2d: depth of input (${O}) must match input depth for filter ${u.shape[2]}.`),r.assert(p.eitherStridesOrDilationsAreOne(l,c),()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${l} and dilations '${c}'`);let f=p.computeConv2DInfo(n.shape,u.shape,l,c,d,b),e;$!=null&&(e=C($,"bias","fused conv2d"),[e]=F(e,h),a==="NHWC"?W.assertAndGetBroadcastShape(f.outShape,e.shape):(r.assert(e.shape.length<=1,()=>`Error in fused conv2d: only supports scalar or 1-D Tensor bias for NCHW format but got the bias of rank-${e.shape.length}.`),r.assert(e.shape.length===0||e.shape[0]===f.outChannels||e.shape[0]===1,()=>`Error in fused conv2d: bias shape (${e.shape}) is not compatible with the number of output channels (${f.outChannels})`)));let B;if(D!=null){let t=D.shape;if(r.assert(t.length<=1||t.length===3,()=>`Error in fused conv2d: only supports scalar, 1-D Tensor or 3-D Tensor PReLU activation weights but got a tensor of rank-${t.length}.`),t.length===1)r.assert(t[0]===1||t[0]===f.outChannels,()=>`Error in fused conv2d: PReLU activation weights (${t}) is not compatible with the number of output channels (${f.outChannels}).`);else if(t.length===3)try{W.assertAndGetBroadcastShape(t,f.outShape)}catch{let i=`Error in fused conv2d: PReLU activation weights (${t}) is not compatible with the output shape of the conv2d (${f.outShape}).`;throw Error(i)}B=C(D,"prelu weights","fused conv2d")}let G=(t,v)=>{r.assert(a==="NHWC",()=>`Error in gradient of fused conv2D: got dataFormat of ${a} but only NHWC is currently supported.`);let[i,g,o,s]=v,k=J(t,o,m);r.assert(p.tupleValuesAreOne(c),()=>`Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${c}'`);let P=j(g.shape,k,i,l,d),L=V(g,k,i.shape,l,d),x=[P,L];if(s!=null){let U=z(s,k);x.push(U)}return x},S={x:n,filter:u,bias:e,preluActivationWeights:B},T={strides:l,pad:d,dataFormat:a,dilations:c,dimRoundingMode:b,activation:m,leakyreluAlpha:H};return $==null?A((v,i,g)=>{let o=y.runKernel(I,S,T);return g([i,v,o]),E&&(o=N(o,[o.shape[1],o.shape[2],o.shape[3]])),{value:o,gradFunc:G}})(n,u):A((v,i,g,o)=>{let s=y.runKernel(I,S,T);return o([i,v,s,g]),E&&(s=N(s,[s.shape[1],s.shape[2],s.shape[3]])),{value:s,gradFunc:G}})(n,u,e)}var lt=Q({fusedConv2d_:X});export{lt as conv2d};
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/fused/conv2d.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
//# sourceMappingURL=conv2d.js.map